{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感谢大家来我的网站学习https://www.captainbed.net\n",
    "\n",
    "PS:本文档带你学习的是tensorflow的1.x版本。tensorflow2.x版本已经与1.x版本有很大不同了。\n",
    "\n",
    "像TensorFlow这样的编程框架不仅仅可以缩短你的开发时间，而且还可以使你的程序运行得更高效更快。因为这些框架都是经过精心设计和高效实现的。所以我是强烈建议大家在实际的商业项目中使用编程框架的。\n",
    "\n",
    "在python中使用tensorflow就像使用numpy库一样，首先要将其导入。导入matplotlib库时可能会出现“No moudle named 'matplotlib'”，解决方法是在anaconda prompt中输入activate tensorflow来激活我们前一篇文章中创建的tensorflow环境，然后再输入pip install matplotlib==3.2.2来安装matplotlib库(后面的3.2.2是版本号，如何有需要的话你也可以安装其它的版本)。以后出现类似找不到库的错误提示都可以用这种方法来解决（注意：有时候会因为网络问题安装失败，因为很多网站都在国外，可以多试试，或者换个时间段试试）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 因为我们安装的是tensorflow2.x，所以要想使用1.x代码的话，就需要使用下面的两行代码。\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# 如果安装的是tensorflow1.x，那么就直接使用下面的一行代码\n",
    "#import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先向大家展示用tensorflow来定义下面的函数。\n",
    "$$loss = \\mathcal{L}(\\hat{y}, y) = (\\hat y^{(i)} - y^{(i)})^2 \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.constant(36, name='y_hat')            # 定义一个tensorflow常量\n",
    "y = tf.constant(39, name='y')                   \n",
    "\n",
    "loss = tf.Variable((y - y_hat)**2, name='loss')  # 定义一个tensorflow变量，这个变量就表示了上面的loss函数\n",
    "\n",
    "init = tf.global_variables_initializer() # 这个可以看作是tensorflow的固定写法，后面会使用init来初始化loss变量                                                 \n",
    "with tf.Session() as session:                    # 创建一个tensorflow的session\n",
    "    session.run(init)                            # 用这个session来执行init初始化操作\n",
    "    print(session.run(loss))                     # 用session来执行loss操作，并将loss的值打印处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到上面的代码，刚接触tensorflow的你可能会感觉到很多地方怪怪的，不是特别理解。这是正常的反应。每一种框架都有其自己的设计特色，当我们和它接触的次数越来越多后，就自然而然地理解那些特色了。所以现在不要求大家能理解它们，顺其自然先往下学就好，后面我保证你能自然而然地茅塞顿开！\n",
    "\n",
    "编写tensorflow程序的一般步骤如下：\n",
    "1. 创建变量，在tensorflow里面有张量（Tensor）一词。 \n",
    "2. 用这些张量来构建一些操作，例如上面的$(\\hat y^{(i)} - y^{(i)})^2$\n",
    "3. 初始化那些张量。这个与我们平时的编程有一点不同，在tensorflow里面创建张量时，并没有对它们进行初始化。要到后面时用特定的语句来初始化那些张量。这样的设计正是tensorflow的一大亮点，它可以大大提升程序的运行效率。后面我们再详细解释它。 \n",
    "4. 创建一个session。tensorflow里面用session来执行操作，前面只是定义了操作，必须要用session才能使那些操作被执行。\n",
    "5. 用session执行前面定义的操作。\n",
    "\n",
    "上面的代码中，我们最开始只创建了一个张量loss，但并没有计算它的值。要到后面执行了session.run(loss)语句后，才开始计算loss的值。给大家打个比方吧，session.run之前的都是在设想，session.run时才是执行那些设想。就像我们建一座大厦一样，session.run之前都是在设计，session.run时才是按设计图动工。\n",
    "\n",
    "下面再给大家举一个更简单的例子来说明tensorflow的这种“设计/动工”的特色:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul_2:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码执行完后，按照我们以往的编程经验来看，print打印出来的应该是20才对。但是tensorflow只是打印出了张量c的一些信息（这些信息表明张量c的维度是空的以及它的类型是int32）。这是为什么呢？因为这些代码只是设计了张量c，还并没有执行它，所以打印出来的只有一些信息而已，并没有实际的值。\n",
    "\n",
    "为了执行上面的设计，我们需要下面的代码。用session.run执行上面的设计后，再次打印出张量c，得到的结果就是20了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要适应tensorflow的这种用法——创建变量和操作，然后对变量进行初始化，然后创建session，最后用session来执行所有操作。\n",
    "\n",
    "下面，我们再来学习一下tensorflow的另一个特性——placehodler——占位符。顾名思义，占位符就是只占着一个位置，这个位置里面的内容是空的，在后面我们就可以往这个位置里面填充各种内容了。就像建造一座大厦，占位符就像是一个个房间，房间里面是空的，后面我们可以往房间里面任意放置各种东西。\n",
    "\n",
    "tensorflow使用feed_dict语法来给占位符填充内容。如下所示，我们创建了一个名为x的占位符，并且在执行session时用feed_dict语法将3填充到了x里面。x被设置成了3，所以session执行2*x这个操作的结果就是6。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow中有个重要的概念——计算图。当我们创建变量和操作时，仅仅是在tensorflow里面构建了一个计算图，计算图里面可以有占位符。这些都只是设计而已，并没有实际的数值也没有被执行。直到创建了session后，就可以用session.run来执行前面设计好的计算图了，在执行计算图时可以往计算图里的占位符中填充内容。同一个计算图，在每次run时，即在每次被执行时都可以往占位符中填充不同的数值。就像一座大厦，可以往房间里面堆放书籍，也可以把书籍搬出来将里面堆放电脑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性函数\n",
    "\n",
    "下面我们用tensorflow来实现人工智能领域中著名的线性函数: $Y = WX + b$。学习过我教程中前面文章的同学已经对这个函数特别熟悉了。在本例中，我们设W的维度是(4,3)，X的维度是(3,1)以及b的是(4,1)。它们里面填充的都是随机数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function():   \n",
    "    \n",
    "    np.random.seed(1)\n",
    " \n",
    "    X = tf.constant(np.random.randn(3, 1), name = \"X\") # 定义一个维度是(3, 1)的常量，randn函数会生成随机数\n",
    "    W = tf.constant(np.random.randn(4, 3), name = \"W\")\n",
    "    b = tf.constant(np.random.randn(4, 1), name = \"b\")\n",
    "    Y = tf.add(tf.matmul(W, X), b)# tf.matmul函数会执行矩阵运算\n",
    "    \n",
    "    # 创建session，然后用run来执行上面定义的操作\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y)\n",
    "    sess.close()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = [[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "print( \"result = \" + str(linear_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid函数\n",
    "上面我们用tensorflow实现了深度学习中著名的线性函数，下面我们再来实现sigmoid这个著名的非线性函数（其实，tensorflow框架已经帮我们实现了这些函数了，我们只需要学会使用它们就可以了）。下面我给大家展示一下如何用placeholder来使用tensorflow中的sigmoid函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, name=\"x\") # 定义一个类型为float32的占位符\n",
    "\n",
    "    sigmoid = tf.sigmoid(x) # 调用tensorflow的sigmoid函数，并且将占位符作为参数传递进去\n",
    "\n",
    "    with tf.Session() as sess: # 创建一个session\n",
    "        # 用run来执行上面定义的sigmoid操作。\n",
    "        # 执行时将外面传入的z填充到占位符x中，也就相当于把z作为参数传入了tensorflow的sigmoid函数中了。\n",
    "        result = sess.run(sigmoid, feed_dict = {x: z}) \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid(12) = 0.9999939\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "细心的同学可能发现有两种方法可以创建tensorflow的session: \n",
    "\n",
    "**方法 1:**\n",
    "```python\n",
    "sess = tf.Session()\n",
    "result = sess.run(..., feed_dict = {...})\n",
    "sess.close() \n",
    "```\n",
    "**方法 2:**\n",
    "```python\n",
    "with tf.Session() as sess: \n",
    "    result = sess.run(..., feed_dict = {...})\n",
    "```\n",
    "\n",
    "两种方法都可以使用，具体看个人的喜好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost函数\n",
    "\n",
    "cost函数也是人工智能领域的一个重要部分。像sigmoid一样，tensorflow也已经帮我们定义好了各种著名的cost函数。在前面的教程中，我们需要写不少python代码来实现下面的cost函数，而如果使用tensorflow框架，只需要一行代码就可以了: \n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\tag{2}$$\n",
    "\n",
    "下面的tensorflow函数一次性帮我们实现了sigmoid和上面的cost函数，上面的cost函数也叫做cross_entropy函数: \n",
    "- `tf.nn.sigmoid_cross_entropy_with_logits(logits = ...,  labels = ...)`\n",
    "\n",
    "logits参数就是我们最后一层神经元输出的z，labels就是我们的真实标签y。上面的tensorflow函数同时实现了sigmoid和cost函数，所以等于一次性实现了下面的函数：\n",
    "\n",
    "$$- \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log \\sigma(z^{[2](i)}) + (1-y^{(i)})\\log (1-\\sigma(z^{[2](i)})\\large )\\small\\tag{2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(z_in, y_in):    \n",
    "    \n",
    "    z = tf.placeholder(tf.float32, name=\"z\") # 创建占位符\n",
    "    y = tf.placeholder(tf.float32, name=\"y\")\n",
    "    \n",
    "    # 使用sigmoid_cross_entropy_with_logits来构建cost操作。\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n",
    "    \n",
    "    # 创建session\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # 将传入的z_in和y_in填充到占位符中，然后执行cost操作\n",
    "    cost = sess.run(cost, feed_dict={z: z_in, y: y_in})\n",
    "\n",
    "    sess.close()\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [0.79813886 0.91301525 0.40318602 0.34115386]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([0.2, 0.4, 0.7, 0.9])\n",
    "cost = cost(logits, np.array([0, 0, 1, 1]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot编码\n",
    "\n",
    "再给大家介绍一个tensorflow中很常用的功能——One Hot编码。在人工智能的编程中，我们经常会遇到多分类问题，我们前面学习的softmax就是用来解决多分类问题的。在多分类编程中，我们的y向量包含了0到C-1的数字，里面的C表示类别的数量。例如，假设C是4，那么我们就需要将下图中左边的向量转换成右边的向量。\n",
    "\n",
    "<img src=\"images/onehot.png\" style=\"width:600px;height:150px;\">\n",
    "\n",
    "右边的向量就叫做one hot向量，中文有人翻译成“独热”向量，因为向量中只有一个元素是1，其它的都是0。例如上图中，最后一个元素是1就表示类型3，倒数第二个元素是1就表示类型2。在之前我们实现纯python编程时，如果要实现上面的转换，我们需要写好几行代码，改用tensorflow框架的话，只需要一行代码: \n",
    "\n",
    "- tf.one_hot(indices, depth, axis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(labels, C_in):\n",
    "    \"\"\"\n",
    "    labels就是真实标签y向量；\n",
    "    C_in就是类别的数量\n",
    "    \"\"\"\n",
    "  \n",
    "    # 创建一个名为C的tensorflow常量，把它的值设为C_in\n",
    "    C = tf.constant(C_in, name='C')\n",
    "    \n",
    "    # 使用one_hot函数构建转换操作，将这个操作命名为one_hot_matrix。\n",
    "    one_hot_matrix = tf.one_hot(indices=labels, depth=C, axis=0)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # 执行one_hot_matrix操作\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "  \n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C_in=4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化0和1\n",
    "\n",
    "最后再介绍两个常用的tensorflow函数，tf.ones()和tf.zeros()。我们将维度信息传入到这两个函数中，它们就会返回填充好1或0的数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones(shape):\n",
    "    \n",
    "    # 将维度信息传入tf.ones中\n",
    "    ones = tf.ones(shape)\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # 执行ones操作\n",
    "    ones = sess.run(ones)\n",
    "    \n",
    "    sess.close()\n",
    "    \n",
    "    return ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (\"ones = \" + str(ones([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好，tensorflow的基本特性就介绍到这里了，大家应该对tensorflow不再陌生了，下篇文章教大家用tensorflow来构建一个完整的人工智能程序！"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
